{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9e493c",
   "metadata": {},
   "source": [
    "The objective of this task is to classify amino acids according to their secondary structure, using the observed counts provided in the trainCount.txt file. The predominant secondary structure represented by the highest counts is assigned as the class for each amino acid. This methodology is employed to achieve accurate classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77bed8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code aims to output the percentage frequency for all the amino acids in the trainCounts for the secondary structures:\n",
    "def frequency_structure(filename):\n",
    "    counts = {}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            letter = tokens[0][0]\n",
    "            if letter not in counts:\n",
    "                counts[letter] = {\"C\": 0, \"H\": 0, \"E\": 0}\n",
    "            if len(tokens[0]) > 1:\n",
    "                if tokens[0][1] == \"C\":\n",
    "                    counts[letter][\"C\"] += int(tokens[1])\n",
    "                elif tokens[0][1] == \"H\":\n",
    "                    counts[letter][\"H\"] += int(tokens[1])\n",
    "                elif tokens[0][1] == \"E\":\n",
    "                    counts[letter][\"E\"] += int(tokens[1])\n",
    "\n",
    "    print(\"First Letter\\tClassification\\tPercentage\")\n",
    "    for letter, letter_counts in counts.items():\n",
    "        total = sum(letter_counts.values())\n",
    "        percentages = {k: v/total*100 for k, v in letter_counts.items()}\n",
    "        max_key = max(percentages, key=percentages.get)\n",
    "        for k, v in letter_counts.items():\n",
    "            percentage = percentages[k]\n",
    "            print(f\"{letter}\\t\\t{max_key}\\t\\t{percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8f14a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Letter\tClassification\tPercentage\n",
      "A\t\tH\t\t31.34%\n",
      "A\t\tH\t\t51.92%\n",
      "A\t\tH\t\t16.74%\n",
      "C\t\tC\t\t40.03%\n",
      "C\t\tC\t\t31.01%\n",
      "C\t\tC\t\t28.96%\n",
      "D\t\tC\t\t54.66%\n",
      "D\t\tC\t\t33.07%\n",
      "D\t\tC\t\t12.27%\n",
      "E\t\tH\t\t34.36%\n",
      "E\t\tH\t\t50.22%\n",
      "E\t\tH\t\t15.42%\n",
      "F\t\tH\t\t30.55%\n",
      "F\t\tH\t\t38.43%\n",
      "F\t\tH\t\t31.03%\n",
      "G\t\tC\t\t66.52%\n",
      "G\t\tC\t\t18.61%\n",
      "G\t\tC\t\t14.87%\n",
      "H\t\tC\t\t44.60%\n",
      "H\t\tC\t\t33.55%\n",
      "H\t\tC\t\t21.85%\n",
      "K\t\tH\t\t39.20%\n",
      "K\t\tH\t\t43.05%\n",
      "K\t\tH\t\t17.76%\n",
      "L\t\tH\t\t26.78%\n",
      "L\t\tH\t\t49.25%\n",
      "L\t\tH\t\t23.97%\n",
      "M\t\tH\t\t32.55%\n",
      "M\t\tH\t\t46.22%\n",
      "M\t\tH\t\t21.23%\n",
      "N\t\tC\t\t56.90%\n",
      "N\t\tC\t\t29.31%\n",
      "N\t\tC\t\t13.79%\n",
      "P\t\tC\t\t70.12%\n",
      "P\t\tC\t\t19.81%\n",
      "P\t\tC\t\t10.07%\n",
      "Q\t\tH\t\t35.09%\n",
      "Q\t\tH\t\t47.93%\n",
      "Q\t\tH\t\t16.98%\n",
      "R\t\tH\t\t35.40%\n",
      "R\t\tH\t\t44.34%\n",
      "R\t\tH\t\t20.26%\n",
      "S\t\tC\t\t49.91%\n",
      "S\t\tC\t\t31.37%\n",
      "S\t\tC\t\t18.72%\n",
      "T\t\tC\t\t43.64%\n",
      "T\t\tC\t\t29.25%\n",
      "T\t\tC\t\t27.11%\n",
      "V\t\tE\t\t25.47%\n",
      "V\t\tE\t\t33.23%\n",
      "V\t\tE\t\t41.30%\n",
      "W\t\tH\t\t29.82%\n",
      "W\t\tH\t\t40.83%\n",
      "W\t\tH\t\t29.35%\n",
      "X\t\tH\t\t25.26%\n",
      "X\t\tH\t\t42.01%\n",
      "X\t\tH\t\t32.73%\n",
      "Y\t\tH\t\t30.96%\n",
      "Y\t\tH\t\t37.37%\n",
      "Y\t\tH\t\t31.67%\n"
     ]
    }
   ],
   "source": [
    "frequency_structure(\"./trainCounts.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f535eb",
   "metadata": {},
   "source": [
    "In this next approach the aim it to focus on assigning a secondary structure to the amino acids based solely on the frequency of the predominant secondary structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c739d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_structure(filename):\n",
    "    counts = {}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            letter = tokens[0][0]\n",
    "            if letter not in counts:\n",
    "                counts[letter] = {\"C\": 0, \"H\": 0, \"E\": 0}\n",
    "            if len(tokens[0]) > 1:\n",
    "                if tokens[0][1] == \"C\":\n",
    "                    counts[letter][\"C\"] += int(tokens[1])\n",
    "                elif tokens[0][1] == \"H\":\n",
    "                    counts[letter][\"H\"] += int(tokens[1])\n",
    "                elif tokens[0][1] == \"E\":\n",
    "                    counts[letter][\"E\"] += int(tokens[1])\n",
    "                    \n",
    "    print(\"Amino acids\\tAssoc_Sec_Structures\\tPercentage\")\n",
    "    for letter, letter_counts in counts.items():\n",
    "        total = sum(letter_counts.values())\n",
    "        percentages = {k: v/total*100 for k, v in letter_counts.items()}\n",
    "        max_key = max(percentages, key=percentages.get)\n",
    "        print(f\"{letter}\\t\\t{max_key}\\t\\t\\t{percentages[max_key]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5d35e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amino acids\tAssoc_Sec_Structures\tPercentage\n",
      "A\t\tH\t\t\t51.92%\n",
      "C\t\tC\t\t\t40.03%\n",
      "D\t\tC\t\t\t54.66%\n",
      "E\t\tH\t\t\t50.22%\n",
      "F\t\tH\t\t\t38.43%\n",
      "G\t\tC\t\t\t66.52%\n",
      "H\t\tC\t\t\t44.60%\n",
      "K\t\tH\t\t\t43.05%\n",
      "L\t\tH\t\t\t49.25%\n",
      "M\t\tH\t\t\t46.22%\n",
      "N\t\tC\t\t\t56.90%\n",
      "P\t\tC\t\t\t70.12%\n",
      "Q\t\tH\t\t\t47.93%\n",
      "R\t\tH\t\t\t44.34%\n",
      "S\t\tC\t\t\t49.91%\n",
      "T\t\tC\t\t\t43.64%\n",
      "V\t\tE\t\t\t41.30%\n",
      "W\t\tH\t\t\t40.83%\n",
      "X\t\tH\t\t\t42.01%\n",
      "Y\t\tH\t\t\t37.37%\n"
     ]
    }
   ],
   "source": [
    "classify_structure(\"./trainCounts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e100746",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amino acids\tAssoc_Sec_Structures\tPercentage\n",
      "A\t\tH\t\t\t51.57%\n",
      "C\t\tC\t\t\t39.56%\n",
      "D\t\tC\t\t\t54.95%\n",
      "E\t\tH\t\t\t49.82%\n",
      "F\t\tH\t\t\t37.36%\n",
      "G\t\tC\t\t\t67.14%\n",
      "H\t\tC\t\t\t44.61%\n",
      "K\t\tH\t\t\t42.81%\n",
      "L\t\tH\t\t\t48.70%\n",
      "M\t\tH\t\t\t44.91%\n",
      "N\t\tC\t\t\t56.51%\n",
      "P\t\tC\t\t\t70.31%\n",
      "Q\t\tH\t\t\t47.01%\n",
      "R\t\tH\t\t\t43.68%\n",
      "S\t\tC\t\t\t50.08%\n",
      "T\t\tC\t\t\t43.54%\n",
      "V\t\tE\t\t\t41.62%\n",
      "W\t\tH\t\t\t39.93%\n",
      "X\t\tH\t\t\t43.59%\n",
      "Y\t\tH\t\t\t36.58%\n"
     ]
    }
   ],
   "source": [
    "classify_structure(\"./testCounts.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153853a9",
   "metadata": {},
   "source": [
    "Using this approach we can see that both the train and test set have classified the amino acids in a similar way across the files using the frequecy approach. This does show that this is a much more reliable approach as there is consistency with the assignemnet of the associated secondary structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c9bef",
   "metadata": {},
   "source": [
    "Test for accuracy of the predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80bbe755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.49057580602822454\n",
      "Test accuracy: 0.4893581866060825\n"
     ]
    }
   ],
   "source": [
    "# Read trainCounts and testCounts files\n",
    "train_counts = {}\n",
    "test_counts = {}\n",
    "\n",
    "with open('./trainCounts.txt') as f:\n",
    "    for line in f:\n",
    "        aa_ss, count = line.strip().split()\n",
    "        count = int(count)\n",
    "        aa, ss = aa_ss[0], aa_ss[1]\n",
    "        if aa not in train_counts:\n",
    "            train_counts[aa] = {}\n",
    "        train_counts[aa][ss] = count\n",
    "\n",
    "with open('./testCounts.txt') as f:\n",
    "    for line in f:\n",
    "        aa_ss, count = line.strip().split()\n",
    "        count = int(count)\n",
    "        aa, ss = aa_ss[0], aa_ss[1]\n",
    "        if aa not in test_counts:\n",
    "            test_counts[aa] = {}\n",
    "        test_counts[aa][ss] = count\n",
    "\n",
    "# Define function to predict secondary structure of a protein sequence\n",
    "def predict_ss(protein_seq, counts):\n",
    "    predicted_ss = ''\n",
    "    for aa in protein_seq:\n",
    "        if aa not in counts:\n",
    "            predicted_ss += 'C'  # default to coil\n",
    "        else:\n",
    "            ss_counts = counts[aa]\n",
    "            predicted_ss += max(ss_counts, key=ss_counts.get)\n",
    "    return predicted_ss\n",
    "\n",
    "# Calculate accuracy on training set\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "with open('./trainSS.txt') as f:\n",
    "    for i in range(0, 4*11860, 4):\n",
    "        protein_name = f.readline().strip()\n",
    "        protein_length = int(f.readline().strip())\n",
    "        protein_seq = f.readline().strip().split('\\t')\n",
    "        protein_ss = f.readline().strip().split('\\t')\n",
    "        predicted_ss = predict_ss(protein_seq, train_counts)\n",
    "        for j in range(protein_length):\n",
    "            if protein_ss[j] == predicted_ss[j]:\n",
    "                train_correct += 1\n",
    "            train_total += 1\n",
    "\n",
    "train_accuracy = train_correct / train_total\n",
    "print('Training accuracy:', train_accuracy)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with open('./testSS.txt') as f:\n",
    "    for i in range(0, 4*3954, 4):\n",
    "        protein_name = f.readline().strip()\n",
    "        protein_length = int(f.readline().strip())\n",
    "        protein_seq = f.readline().strip().split('\\t')\n",
    "        protein_ss = f.readline().strip().split('\\t')\n",
    "        predicted_ss = predict_ss(protein_seq, test_counts)\n",
    "        for j in range(protein_length):\n",
    "            if protein_ss[j] == predicted_ss[j]:\n",
    "                test_correct += 1\n",
    "            test_total += 1\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b85ab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic predictor accuracy on training set: 0.22\n",
      "Basic predictor accuracy on test set: 0.22\n"
     ]
    }
   ],
   "source": [
    "def parse_counts(filename):\n",
    "    counts = {}\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            letter = tokens[0][0]\n",
    "            if letter not in counts:\n",
    "                counts[letter] = {\"C\": 0, \"H\": 0, \"E\": 0}\n",
    "            if len(tokens[0]) > 1:\n",
    "                if tokens[0][1] == \"C\":\n",
    "                    counts[letter][\"C\"] += int(tokens[1])\n",
    "                elif tokens[0][1] == \"H\":\n",
    "                    counts[letter][\"H\"] += int(tokens[1])\n",
    "                elif tokens[0][1] == \"E\":\n",
    "                    counts[letter][\"E\"] += int(tokens[1])\n",
    "    return counts\n",
    "\n",
    "def compute_accuracy(predictor, counts):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for letter, letter_counts in counts.items():\n",
    "        for classification in [\"C\", \"H\", \"E\"]:\n",
    "            for count in range(letter_counts[classification]):\n",
    "                total += 1\n",
    "                if predictor(letter) == classification:\n",
    "                    correct += 1\n",
    "    return correct/total\n",
    "\n",
    "# Parse the training and test sets\n",
    "train_counts = parse_counts(\"./trainCounts.txt\")\n",
    "test_counts = parse_counts(\"./testCounts.txt\")\n",
    "\n",
    "# Define a basic predictor that always predicts \"C\"\n",
    "def basic_predictor(letter):\n",
    "    return \"E\"\n",
    "\n",
    "# Compute the accuracy of the basic predictor on the training set and test set\n",
    "train_accuracy = compute_accuracy(basic_predictor, train_counts)\n",
    "test_accuracy = compute_accuracy(basic_predictor, test_counts)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Basic predictor accuracy on training set: {train_accuracy:.2f}\")\n",
    "print(f\"Basic predictor accuracy on test set: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea1fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
